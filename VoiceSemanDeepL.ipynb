{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import pickle\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm  #pip install tqdm :)\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_dict = {\n",
    "    \"SGD\": optim.SGD,\n",
    "    \"Adagrad\": optim.Adagrad,\n",
    "    \"Adam\": optim.Adam\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0183, 0.4314, 0.5433],\n",
      "        [0.6017, 0.4753, 0.6941],\n",
      "        [0.9765, 0.5078, 0.6185],\n",
      "        [0.8081, 0.3791, 0.9430],\n",
      "        [0.1166, 0.6464, 0.2400]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"y\", \"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(zip_file_path):  \n",
    "    global df\n",
    "    data_list = []\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        for file in zip_ref.namelist():\n",
    "            if file.endswith('.pkl'):\n",
    "                with zip_ref.open(file) as pkl_file:\n",
    "                    data = pickle.load(pkl_file)\n",
    "                    \n",
    "                    audio_features = data['audio_data']\n",
    "                    \n",
    "                    if audio_features.shape[0] > 0: \n",
    "                        valence = data.get(\"valence\")\n",
    "                        data_list.append({\"y\": valence, \"X\": audio_features})\n",
    "    \n",
    "    # Use pd.concat to create the DataFrame\n",
    "    df = pd.concat([df, pd.DataFrame(data_list)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    max_length = max(x.shape[0] for x in X)\n",
    "    X_padded = np.array([np.pad(x, (0, max_length - x.shape[0]), mode='constant') for x in X], dtype='float32')\n",
    "\n",
    "    # Normalize the padded data\n",
    "    X_normalized = (X_padded - np.mean(X_padded)) / np.std(X_padded)\n",
    "    \n",
    "    return X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amitanshu Ghosh\\AppData\\Local\\Temp\\ipykernel_9468\\3939526362.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame(data_list)], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.25</td>\n",
       "      <td>[-1.0349686e-05, -8.201167e-06, 1.5248549e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.50</td>\n",
       "      <td>[0.0004993363, 0.001089146, 0.0012895092, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.25</td>\n",
       "      <td>[-4.832544e-06, -8.244775e-06, -3.7053242e-06,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.75</td>\n",
       "      <td>[-0.00050674484, -0.0009754167, -0.0010292103,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.50</td>\n",
       "      <td>[2.7288927e-05, 2.9628214e-05, 8.091243e-05, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y                                                  X\n",
       "0  1.25  [-1.0349686e-05, -8.201167e-06, 1.5248549e-05,...\n",
       "1  3.50  [0.0004993363, 0.001089146, 0.0012895092, 0.00...\n",
       "2  3.25  [-4.832544e-06, -8.244775e-06, -3.7053242e-06,...\n",
       "3  3.75  [-0.00050674484, -0.0009754167, -0.0010292103,...\n",
       "4  3.50  [2.7288927e-05, 2.9628214e-05, 8.091243e-05, 0..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_file = r\"C:\\\\Users\\\\Amitanshu Ghosh\\\\Desktop\\\\train.zip\"\n",
    "#zip_file = r\"C:\\Users\\Danie\\Downloads\\train.zip\"\n",
    "load_data(zip_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[\"X\"].values, dtype=object)\n",
    "X = preprocess_data(X)\n",
    "y = df[\"y\"].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)  # Add channel dimension\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(-1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        super(AudioModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(8)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(16)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def _get_conv_output_size(self, input_size):\n",
    "        x = torch.zeros(1, 1, input_size)  # Dummy input to get the output size\n",
    "        x = self.pool1(self.batch_norm1(torch.relu(self.conv1(x))))\n",
    "        x = self.pool2(self.batch_norm2(torch.relu(self.conv2(x))))\n",
    "        return x.shape[2]\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # Switch batch and channel dimensions for Conv1D\n",
    "        x = self.pool1(self.batch_norm1(torch.relu(self.conv1(x))))\n",
    "        x = self.pool2(self.batch_norm2(torch.relu(self.conv2(x))))\n",
    "        x = x.transpose(1, 2)  # Switch back to batch-first format for LSTM\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x[:, -1, :])  # Use the output of the last time step\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioModel(\n",
       "  (conv1): Conv1d(1, 8, kernel_size=(3,), stride=(1,))\n",
       "  (batch_norm1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(8, 16, kernel_size=(3,), stride=(1,))\n",
       "  (batch_norm2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (lstm): LSTM(16, 16, batch_first=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 8\n",
    "\n",
    "learning_rate = 0.001\n",
    "input_size = 16\n",
    "hidden_size = 16\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "model = AudioModel(input_size, hidden_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train.to(device), X_test.to(device), y_train.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, loss, file_path):\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(state, file_path)\n",
    "    print(f\"Model saved to {file_path}\")\n",
    "\n",
    "def evaluate_model(model, criterion):\n",
    "    batch_size = 8\n",
    "    eval_batch_size = 4  \n",
    "    num_test_samples = X_test.size(0)\n",
    "    num_batches = (num_test_samples + eval_batch_size - 1) // eval_batch_size\n",
    "\n",
    "    model.eval()\n",
    "    mse_loss = 0.0\n",
    "    mae_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_batches):\n",
    "            start_idx = i * eval_batch_size\n",
    "            end_idx = min((i + 1) * eval_batch_size, num_test_samples)\n",
    "            batch_x = X_test[start_idx:end_idx]\n",
    "            batch_y = y_test[start_idx:end_idx]\n",
    "\n",
    "            batch_pred = model(batch_x).cpu().numpy()\n",
    "\n",
    "            # Compute MSE and MAE \n",
    "            batch_mse = mean_squared_error(batch_y.cpu().numpy(), batch_pred)\n",
    "            batch_mae = mean_absolute_error(batch_y.cpu().numpy(), batch_pred)\n",
    "\n",
    "            # Accumulate losses\n",
    "            mse_loss += batch_mse * (end_idx - start_idx)\n",
    "            mae_loss += batch_mae * (end_idx - start_idx)\n",
    "\n",
    "    # Compute average losses\n",
    "    mse_loss /= num_test_samples\n",
    "    mae_loss /= num_test_samples\n",
    "\n",
    "    return mse_loss, mae_loss\n",
    "\n",
    "def train_model(model, num_epochs, criterion, optimizer, save_path, optimizer_name):\n",
    "    loss_per_epoch = []\n",
    "    mse_per_epoch = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        permutation = torch.randperm(X_train.size()[0])\n",
    "        epoch_loss = 0\n",
    "        num_batches = X_train.size()[0] // batch_size\n",
    "\n",
    "        with tqdm(total=num_batches, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\") as pbar:\n",
    "            for i in range(0, X_train.size()[0], batch_size):\n",
    "                indices = permutation[i:i + batch_size]\n",
    "                batch_x, batch_y = X_train[indices], y_train[indices]\n",
    " \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "                pbar.update(1)\n",
    "        \n",
    "        mse_loss, mae_loss = evaluate_model(model, criterion)\n",
    "        mse_per_epoch.append(mse_loss)\n",
    "        loss_per_epoch.append(epoch_loss / num_batches)\n",
    "\n",
    "\n",
    "        # Saving model per epoch\n",
    "        file_name = f\"model_{optimizer_name}_epoch_{epoch+1}.pth\"\n",
    "        file_path = os.path.join(save_path, optimizer_name, file_name)\n",
    "        save_model(model, optimizer, epoch+1, epoch_loss / num_batches, file_path)\n",
    "        \n",
    "    return loss_per_epoch, mse_per_epoch\n",
    "\n",
    "def plot_search(results):\n",
    "\n",
    "    \n",
    "    # Extract relevant information for the heatmap\n",
    "    lr_values = [result['lr'] for result in results]\n",
    "    hidden_size_values = [result['hidden_size'] for result in results]\n",
    "    val_loss_values = [result['loss'] for result in results]\n",
    "\n",
    "    # Create a heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    heatmap = plt.scatter(lr_values, hidden_size_values, c=val_loss_values, cmap='RdYlGn', marker='o', s=100)\n",
    "    plt.colorbar(heatmap, label='Validation Loss')\n",
    "    plt.xscale('log')  \n",
    "\n",
    "    \n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Hidden Size')\n",
    "    plt.title('Hyperparameter Search')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_names = [\"SGD\", \"Adagrad\", \"Adam\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"C:\\\\Users\\\\Amitanshu Ghosh\\\\Desktop\\\\test_models\"\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/1055 [00:01<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m optimizer_class \u001b[38;5;241m=\u001b[39m optimizer_dict[optimizer_name]\n\u001b[0;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optimizer_class(params\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m---> 13\u001b[0m loss_evolution, mse_evolution \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m all_loss_evolution\u001b[38;5;241m.\u001b[39mappend(loss_evolution)\n\u001b[0;32m     15\u001b[0m all_mse_evolution\u001b[38;5;241m.\u001b[39mappend(mse_evolution)\n",
      "Cell \u001b[1;32mIn[14], line 62\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, num_epochs, criterion, optimizer, save_path, optimizer_name)\u001b[0m\n\u001b[0;32m     60\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch_x)\n\u001b[0;32m     61\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n\u001b[1;32m---> 62\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     65\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Amitanshu Ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Amitanshu Ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Amitanshu Ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "names = []\n",
    "all_loss_evolution = []\n",
    "all_mse_evolution = []\n",
    "\n",
    "for optimizer_name in optimizer_names:\n",
    "    # Directory for the optimizer\n",
    "    optimizer_path = os.path.join(save_path, optimizer_name)\n",
    "    os.makedirs(optimizer_path, exist_ok=True)\n",
    "    \n",
    "    optimizer_class = optimizer_dict[optimizer_name]\n",
    "    optimizer = optimizer_class(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "    loss_evolution, mse_evolution = train_model(model, epochs, criterion, optimizer, save_path, optimizer_name)\n",
    "    all_loss_evolution.append(loss_evolution)\n",
    "    all_mse_evolution.append(mse_evolution)\n",
    "    \n",
    "    plt.plot(mse_evolution, label=f\"{optimizer_name}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(hidden_size, learning_rate, criterion, num_epochs):\n",
    "    # Create the model\n",
    "    model = AudioModel(input_size, hidden_size)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Temporary save path for models during evaluation\n",
    "    temp_save_path = \"C:\\\\Users\\\\Amitanshu Ghosh\\\\Desktop\\\\test_model_post_train\"\n",
    "    \n",
    "   # Does directory exist\n",
    "    if not os.path.exists(temp_save_path):\n",
    "        os.makedirs(temp_save_path)\n",
    "    \n",
    "    # Train the model\n",
    "    loss_evolution, mse_evolution = train_model(model, num_epochs=num_epochs, criterion=criterion, optimizer=optimizer, save_path=temp_save_path, optimizer_name=\"Adam\")\n",
    "    return loss_evolution[-1], mse_evolution[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 1056batch [12:10,  1.45batch/s, loss=0.692]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 1056batch [13:04,  1.35batch/s, loss=1.91]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 1056batch [13:39,  1.29batch/s, loss=0.906]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 1056batch [13:33,  1.30batch/s, loss=0.262]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 1056batch [14:36,  1.20batch/s, loss=0.718]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_5.pth\n",
      "1. Learning rate: 0.09778 and hidden size: 16\n",
      "\tValidation mse: 0.68194\n",
      "\tValidation loss: 0.71194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 1056batch [16:00,  1.10batch/s, loss=1.53]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 1056batch [08:02,  2.19batch/s, loss=0.764]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 1056batch [09:09,  1.92batch/s, loss=1.15]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 1056batch [09:58,  1.76batch/s, loss=1.1]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 1056batch [07:14,  2.43batch/s, loss=0.247]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_5.pth\n",
      "2. Learning rate: 0.01204 and hidden size: 26\n",
      "\tValidation mse: 0.68367\n",
      "\tValidation loss: 0.69408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 1056batch [07:27,  2.36batch/s, loss=1.18]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 1056batch [07:26,  2.37batch/s, loss=0.607]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 1056batch [07:39,  2.30batch/s, loss=0.81]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 1056batch [08:02,  2.19batch/s, loss=0.731]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 1056batch [07:03,  2.49batch/s, loss=0.511]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_5.pth\n",
      "3. Learning rate: 0.005785 and hidden size: 21\n",
      "\tValidation mse: 0.67705\n",
      "\tValidation loss: 0.71796\n",
      "\n",
      "Best parameters found:\n",
      " - Learning rate: 0.012038\n",
      " - Hidden size: 26\n",
      " - Validation mse: 0.68%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Coarse Random Search\n",
    "coarse_trials = 3\n",
    "num_epochs = 5\n",
    "coarse_results = []\n",
    "\n",
    "for i in range(coarse_trials):\n",
    "    lr = 10.0**random.uniform(-3, -1)  # Random log-uniform sampling within the range 0.001 to 0.1\n",
    "    hidden_size = int(2**random.uniform(4, 6))\n",
    "\n",
    "    val_loss, val_mse = train_eval(hidden_size, lr, criterion, num_epochs)\n",
    "    coarse_results.append({'lr': lr, 'hidden_size': hidden_size, 'loss': val_loss, 'mse': val_mse})\n",
    "    print(f\"{i+1}. Learning rate: {lr:.4} and hidden size: {hidden_size}\")\n",
    "    print(f\"\\tValidation mse: {val_mse:.5}\\n\\tValidation loss: {val_loss:.5}\\n\")\n",
    "\n",
    "# Find the best parameters from coarse search\n",
    "best_coarse_params = min(coarse_results, key=lambda x: x['loss'])\n",
    "print(f\"Best parameters found:\\n - Learning rate: {best_coarse_params['lr']:.5}\\n - Hidden size: {best_coarse_params['hidden_size']}\\n - Validation mse: {best_coarse_params['mse']:.2}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.01083 and hidden size: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/1055 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 1056batch [06:45,  2.60batch/s, loss=0.514]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 1056batch [06:45,  2.60batch/s, loss=0.506]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 1056batch [06:37,  2.65batch/s, loss=1.44]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 1056batch [06:52,  2.56batch/s, loss=1.06]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 1056batch [06:46,  2.60batch/s, loss=0.37]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_5.pth\n",
      "\tValidation mse: 0.67709\n",
      "\tValidation loss: 0.694\n",
      "\n",
      "Learning rate: 0.008957 and hidden size: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 1056batch [07:08,  2.46batch/s, loss=1.47]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 1056batch [07:10,  2.45batch/s, loss=1.1]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 1056batch [07:17,  2.41batch/s, loss=0.511]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 1056batch [06:48,  2.59batch/s, loss=0.627]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 1056batch [07:28,  2.36batch/s, loss=0.772]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_5.pth\n",
      "\tValidation mse: 0.67394\n",
      "\tValidation loss: 0.70175\n",
      "\n",
      "Learning rate: 0.006617 and hidden size: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 1056batch [07:08,  2.47batch/s, loss=0.675]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 1056batch [07:20,  2.40batch/s, loss=1.57]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 1056batch [07:01,  2.50batch/s, loss=0.611]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 1056batch [07:24,  2.38batch/s, loss=0.321]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 1056batch [07:20,  2.40batch/s, loss=0.827]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Amitanshu Ghosh\\Desktop\\test_model_post_train\\Adam\\model_Adam_epoch_5.pth\n",
      "\tValidation mse: 0.67855\n",
      "\tValidation loss: 0.71915\n",
      "\n",
      "Best parameters found with coarse search:\n",
      " - Learning rate: 0.012038\n",
      " - Hidden size: 26\n",
      " - Validation mse: 0.68%\n",
      "Best parameters found with fine search:\n",
      " - Learning rate: 0.010832\n",
      " - Hidden size: 22\n",
      " - Validation mse: 0.68%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a model with hidden size 22 and learning rate 0.012038\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m loss_evolution, mse_evolution \u001b[38;5;241m=\u001b[39m train_model(model\u001b[38;5;241m=\u001b[39mmodel, optimizer\u001b[38;5;241m=\u001b[39moptimizer, num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, criterion\u001b[38;5;241m=\u001b[39mcriterion, save_path\u001b[38;5;241m=\u001b[39m\u001b[43msave_path\u001b[49m, optimizer_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(mse_evolution)\n\u001b[0;32m     29\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'save_path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fine_trials = 3\n",
    "fine_results = []\n",
    "\n",
    "for _ in range(fine_trials):\n",
    "    lr = best_coarse_params['lr'] * 2.0**random.uniform(-1, 1)  # Fine search around the best LR\n",
    "    hidden_size = int(best_coarse_params['hidden_size'] * random.uniform(0.8, 1.2))  # Fine search around the best hidden size\n",
    "\n",
    "    print(f\"Learning rate: {lr:.4} and hidden size: {hidden_size}\")\n",
    "    val_loss, val_mse = train_eval(hidden_size, lr, criterion, num_epochs)\n",
    "    print(f\"\\tValidation mse: {val_mse:.5}\\n\\tValidation loss: {val_loss:.5}\\n\")\n",
    "    fine_results.append({'lr': lr, 'hidden_size': hidden_size, 'loss': val_loss, 'mse': val_mse})\n",
    "\n",
    "# Find the best parameters from fine search\n",
    "best_fine_params = min(fine_results, key=lambda x: x['loss'])\n",
    "\n",
    "print(f\"Best parameters found with coarse search:\\n - Learning rate: {best_coarse_params['lr']:.5}\\n - Hidden size: {best_coarse_params['hidden_size']}\\n - Validation mse: {best_coarse_params['mse']:.2}%\")\n",
    "print(f\"Best parameters found with fine search:\\n - Learning rate: {best_fine_params['lr']:.5}\\n - Hidden size: {best_fine_params['hidden_size']}\\n - Validation mse: {best_fine_params['mse']:.2}%\")\n",
    "plot_search(coarse_results + fine_results)\n",
    "\n",
    "print(f\"Training a model with hidden size {best_fine_params['hidden_size']} and learning rate {best_coarse_params['lr']:.5}\")\n",
    "model = AudioModel(input_size, best_fine_params['hidden_size'])\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=best_coarse_params['lr'])  # For SGD momentum=0.9, nesterov=True)\n",
    "\n",
    "num_epochs = 3\n",
    "# Train the model\n",
    "loss_evolution, mse_evolution = train_model(model=model, optimizer=optimizer, num_epochs=num_epochs, criterion=criterion, save_path=save_path, optimizer_name=\"Adam\")\n",
    "plt.plot(mse_evolution)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"mse\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_loss, eval_mse = evaluate_model(model, criterion)\n",
    "print(f\"mse on the test set: {eval_mse*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.005067 and hidden size: 21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(best_coarse_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.2\u001b[39m))  \u001b[38;5;66;03m# Fine search around the best hidden size\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearning rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and hidden size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m val_loss, val_mse \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mValidation mse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_mse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mValidation loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m fine_results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: lr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m'\u001b[39m: hidden_size, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: val_loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m: val_mse})\n",
      "Cell \u001b[1;32mIn[22], line 15\u001b[0m, in \u001b[0;36mtrain_eval\u001b[1;34m(hidden_size, learning_rate, criterion, num_epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(temp_save_path)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m loss_evolution, mse_evolution \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp_save_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAdam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_evolution[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], mse_evolution[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[34], line 18\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, optimizer, num_epochs, criterion, save_path, optimizer_name)\u001b[0m\n\u001b[0;32m     16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch_x)\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     21\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Amitanshu Ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Amitanshu Ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Amitanshu Ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_fine_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining a model with hidden size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbest_fine_params\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and learning rate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_coarse_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m AudioModel(input_size, best_fine_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_fine_params' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Training a model with hidden size {best_fine_params['hidden_size']} and learning rate {best_coarse_params['lr']:.5}\")\n",
    "model = AudioModel(input_size, best_fine_params['hidden_size'])\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=best_coarse_params['lr']) #for SGD momentum=0.9, nesterov=True)\n",
    "#save_path = \"C:\\\\Users\\\\Amitanshu Ghosh\\\\Desktop\\\\test_model_post_train\"\n",
    "num_epochs = 10\n",
    "# Train the model\n",
    "loss_evolution, mse_evolution = train_model(model, optimizer, num_epochs=num_epochs, criterion=criterion, save_path= save_path, optimizer_name=\"Adam\")\n",
    "plt.plot(mse_evolution)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"mse\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_loss, eval_mse = evaluate_model(model, criterion)\n",
    "print(f\"mse on the test set: {eval_mse*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
